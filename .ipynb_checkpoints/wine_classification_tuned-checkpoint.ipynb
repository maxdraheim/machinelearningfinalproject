{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Classification\n",
    "## ESE417 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1599, 12)\n",
      "\n",
      "Original quality distribution:\n",
      "quality\n",
      "3     10\n",
      "4     53\n",
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "8     18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'winequality-red.csv'  # Update path if needed\n",
    "\n",
    "columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', \n",
    "           'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', \n",
    "           'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=';', skiprows=1, names=columns)\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"\\nOriginal quality distribution:\")\n",
    "print(df['quality'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning - Outlier Removal\n",
    "\n",
    "Remove outliers using the IQR method to reduce noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples removed: 464\n",
      "Clean dataset shape: (1135, 12)\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers using IQR method\n",
    "def remove_outliers(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    return df_clean\n",
    "\n",
    "# Apply to feature columns only\n",
    "feature_cols = df.columns.drop('quality')\n",
    "df_clean = remove_outliers(df, feature_cols)\n",
    "\n",
    "print(f\"Samples removed: {len(df) - len(df_clean)}\")\n",
    "print(f\"Clean dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Grouping\n",
    "\n",
    "Based on EDA, the original 6 quality classes are imbalanced. We group them into 3 classes:\n",
    "- Low (3-4)\n",
    "- Medium (5-6)  \n",
    "- High (7-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class distribution:\n",
      "quality_group\n",
      "0     34\n",
      "1    962\n",
      "2    139\n",
      "Name: count, dtype: int64\n",
      "\n",
      "0 = Low (3-4), 1 = Medium (5-6), 2 = High (7-8)\n"
     ]
    }
   ],
   "source": [
    "# Group quality into 3 classes\n",
    "def group_quality(q):\n",
    "    if q <= 4:\n",
    "        return 0  # Low\n",
    "    elif q <= 6:\n",
    "        return 1  # Medium\n",
    "    else:\n",
    "        return 2  # High\n",
    "\n",
    "df_clean['quality_group'] = df_clean['quality'].apply(group_quality)\n",
    "\n",
    "print(\"New class distribution:\")\n",
    "print(df_clean['quality_group'].value_counts().sort_index())\n",
    "print(\"\\n0 = Low (3-4), 1 = Medium (5-6), 2 = High (7-8)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 908\n",
      "Test samples: 227\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = df_clean.drop(['quality', 'quality_group'], axis=1)\n",
    "y = df_clean['quality_group']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Baseline:\n",
      "Accuracy: 0.8767\n"
     ]
    }
   ],
   "source": [
    "# Baseline SVM\n",
    "svm = SVC(kernel='rbf', random_state=RANDOM_STATE)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "svm_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM Baseline:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svm_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Tuned (C=10):\n",
      "Accuracy: 0.8811\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.25      0.14      0.18         7\n",
      "      Medium       0.91      0.95      0.93       192\n",
      "        High       0.73      0.57      0.64        28\n",
      "\n",
      "    accuracy                           0.88       227\n",
      "   macro avg       0.63      0.56      0.58       227\n",
      "weighted avg       0.87      0.88      0.87       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuned SVM - adjusted C\n",
    "svm_tuned = SVC(kernel='rbf', C=10, random_state=RANDOM_STATE)\n",
    "svm_tuned.fit(X_train_scaled, y_train)\n",
    "svm_tuned_pred = svm_tuned.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM Tuned (C=10):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svm_tuned_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, svm_tuned_pred, target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Baseline:\n",
      "Accuracy: 0.8722\n"
     ]
    }
   ],
   "source": [
    "# Baseline Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Random Forest Baseline:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Tuned (n=200, depth=15):\n",
      "Accuracy: 0.8855\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.00      0.00      0.00         7\n",
      "      Medium       0.89      0.98      0.94       192\n",
      "        High       0.80      0.43      0.56        28\n",
      "\n",
      "    accuracy                           0.89       227\n",
      "   macro avg       0.56      0.47      0.50       227\n",
      "weighted avg       0.85      0.89      0.86       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuned Random Forest - more trees and limit depth to prevent overfitting(small dataset)\n",
    "rf_tuned = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "rf_tuned.fit(X_train_scaled, y_train)\n",
    "rf_tuned_pred = rf_tuned.predict(X_test_scaled)\n",
    "\n",
    "print(\"Random Forest Tuned (n=200, depth=15):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_tuned_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_tuned_pred, target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Artificial Neural Network (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Neural Network\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=RANDOM_STATE)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "mlp_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "print(\"Neural Network Baseline:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, mlp_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned Neural Network - add second layer and regularization\n",
    "mlp_tuned = MLPClassifier(hidden_layer_sizes=(100, 50), alpha=0.01, max_iter=1000, random_state=RANDOM_STATE)\n",
    "mlp_tuned.fit(X_train_scaled, y_train)\n",
    "mlp_tuned_pred = mlp_tuned.predict(X_test_scaled)\n",
    "\n",
    "print(\"Neural Network Tuned (layers=100,50, alpha=0.01):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, mlp_tuned_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, mlp_tuned_pred, target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"Logistic Regression Baseline:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned Logistic Regression - adjust regularization\n",
    "lr_tuned = LogisticRegression(C=0.5, max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr_tuned.fit(X_train_scaled, y_train)\n",
    "lr_tuned_pred = lr_tuned.predict(X_test_scaled)\n",
    "\n",
    "print(\"Logistic Regression Tuned (C=0.5):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_tuned_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, lr_tuned_pred, target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "print(\"KNN Baseline:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, knn_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned KNN - adjust k and use distance weighting\n",
    "knn_tuned = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "knn_tuned.fit(X_train_scaled, y_train)\n",
    "knn_tuned_pred = knn_tuned.predict(X_test_scaled)\n",
    "\n",
    "print(\"KNN Tuned (k=7, weights=distance):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, knn_tuned_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, knn_tuned_pred, target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Results Comparison\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Model':<25} {'Baseline':<12} {'Tuned':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'SVM':<25} {accuracy_score(y_test, svm_pred):<12.4f} {accuracy_score(y_test, svm_tuned_pred):<12.4f}\")\n",
    "print(f\"{'Random Forest':<25} {accuracy_score(y_test, rf_pred):<12.4f} {accuracy_score(y_test, rf_tuned_pred):<12.4f}\")\n",
    "print(f\"{'Neural Network':<25} {accuracy_score(y_test, mlp_pred):<12.4f} {accuracy_score(y_test, mlp_tuned_pred):<12.4f}\")\n",
    "print(f\"{'Logistic Regression':<25} {accuracy_score(y_test, lr_pred):<12.4f} {accuracy_score(y_test, lr_tuned_pred):<12.4f}\")\n",
    "print(f\"{'KNN':<25} {accuracy_score(y_test, knn_pred):<12.4f} {accuracy_score(y_test, knn_tuned_pred):<12.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
