{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Classification\n",
    "## ESE417 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1599, 12)\n",
      "\n",
      "Quality distribution:\n",
      "quality\n",
      "3     10\n",
      "4     53\n",
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "8     18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'winequality-red.csv'  # Update path if needed\n",
    "\n",
    "columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', \n",
    "           'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', \n",
    "           'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=';', skiprows=1, names=columns)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nQuality distribution:\")\n",
    "print(df['quality'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 1: BASELINE MODELS (No Preprocessing)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1279\n",
      "Test samples: 320\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Split features and target (original 6 classes)\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Number of classes: {y.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Baseline Accuracy: 0.6250\n",
      "Random Forest Baseline Accuracy: 0.6813\n",
      "Neural Network Baseline Accuracy: 0.6375\n",
      "Logistic Regression Baseline Accuracy: 0.5906\n",
      "KNN Baseline Accuracy: 0.6094\n"
     ]
    }
   ],
   "source": [
    "# Store baseline results\n",
    "baseline_results = {}\n",
    "\n",
    "# SVM\n",
    "svm_base = SVC(kernel='rbf', random_state=RANDOM_STATE)\n",
    "svm_base.fit(X_train_scaled, y_train)\n",
    "svm_base_pred = svm_base.predict(X_test_scaled)\n",
    "baseline_results['SVM'] = accuracy_score(y_test, svm_base_pred)\n",
    "print(f\"SVM Baseline Accuracy: {baseline_results['SVM']:.4f}\")\n",
    "\n",
    "# Random Forest\n",
    "rf_base = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rf_base.fit(X_train_scaled, y_train)\n",
    "rf_base_pred = rf_base.predict(X_test_scaled)\n",
    "baseline_results['Random Forest'] = accuracy_score(y_test, rf_base_pred)\n",
    "print(f\"Random Forest Baseline Accuracy: {baseline_results['Random Forest']:.4f}\")\n",
    "\n",
    "# Neural Network\n",
    "mlp_base = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=RANDOM_STATE)\n",
    "mlp_base.fit(X_train_scaled, y_train)\n",
    "mlp_base_pred = mlp_base.predict(X_test_scaled)\n",
    "baseline_results['Neural Network'] = accuracy_score(y_test, mlp_base_pred)\n",
    "print(f\"Neural Network Baseline Accuracy: {baseline_results['Neural Network']:.4f}\")\n",
    "\n",
    "# Logistic Regression\n",
    "lr_base = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr_base.fit(X_train_scaled, y_train)\n",
    "lr_base_pred = lr_base.predict(X_test_scaled)\n",
    "baseline_results['Logistic Regression'] = accuracy_score(y_test, lr_base_pred)\n",
    "print(f\"Logistic Regression Baseline Accuracy: {baseline_results['Logistic Regression']:.4f}\")\n",
    "\n",
    "# KNN\n",
    "knn_base = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_base.fit(X_train_scaled, y_train)\n",
    "knn_base_pred = knn_base.predict(X_test_scaled)\n",
    "baseline_results['KNN'] = accuracy_score(y_test, knn_base_pred)\n",
    "print(f\"KNN Baseline Accuracy: {baseline_results['KNN']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "BASELINE RESULTS SUMMARY\n",
      "========================================\n",
      "Random Forest        0.6813\n",
      "Neural Network       0.6375\n",
      "SVM                  0.6250\n",
      "KNN                  0.6094\n",
      "Logistic Regression  0.5906\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"BASELINE RESULTS SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "for model, acc in sorted(baseline_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{model:<20} {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 2: IMPROVED MODELS (With Data Cleaning + Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning - Outlier Removal Using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original samples: 1599\n",
      "After outlier removal: 1135\n",
      "Samples removed: 464 (29.0%)\n",
      "\n",
      "Cleaned quality distribution:\n",
      "quality\n",
      "3      2\n",
      "4     32\n",
      "5    490\n",
      "6    472\n",
      "7    130\n",
      "8      9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers using IQR method\n",
    "def remove_outliers(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    return df_clean\n",
    "\n",
    "# Apply to feature columns\n",
    "feature_cols = df.columns.drop('quality')\n",
    "df_clean = remove_outliers(df, feature_cols)\n",
    "\n",
    "print(f\"Original samples: {len(df)}\")\n",
    "print(f\"After outlier removal: {len(df_clean)}\")\n",
    "print(f\"Samples removed: {len(df) - len(df_clean)} ({100*(len(df)-len(df_clean))/len(df):.1f}%)\")\n",
    "print(f\"\\nCleaned quality distribution:\")\n",
    "print(df_clean['quality'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing on Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 908\n",
      "Test samples: 227\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X_clean = df_clean.drop('quality', axis=1)\n",
    "y_clean = df_clean['quality']\n",
    "\n",
    "# Train-test split\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.2, random_state=RANDOM_STATE, stratify=y_clean\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler_c = StandardScaler()\n",
    "X_train_c_scaled = scaler_c.fit_transform(X_train_c)\n",
    "X_test_c_scaled = scaler_c.transform(X_test_c)\n",
    "\n",
    "print(f\"Training samples: {len(X_train_c)}\")\n",
    "print(f\"Test samples: {len(X_test_c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tuned Model Training (On Cleaned Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Tuned Accuracy: 0.6300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      0.17      0.25         6\n",
      "           5       0.67      0.71      0.69        98\n",
      "           6       0.60      0.62      0.61        94\n",
      "           7       0.64      0.54      0.58        26\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.63       227\n",
      "   macro avg       0.40      0.34      0.36       227\n",
      "weighted avg       0.62      0.63      0.62       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store tuned results\n",
    "tuned_results = {}\n",
    "\n",
    "# SVM - increase C for better fit\n",
    "svm_tuned = SVC(kernel='rbf', C=10, random_state=RANDOM_STATE)\n",
    "svm_tuned.fit(X_train_c_scaled, y_train_c)\n",
    "svm_tuned_pred = svm_tuned.predict(X_test_c_scaled)\n",
    "tuned_results['SVM'] = accuracy_score(y_test_c, svm_tuned_pred)\n",
    "print(f\"SVM Tuned Accuracy: {tuned_results['SVM']:.4f}\")\n",
    "print(classification_report(y_test_c, svm_tuned_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Tuned Accuracy: 0.6872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.70      0.80      0.75        98\n",
      "           6       0.66      0.69      0.68        94\n",
      "           7       0.71      0.46      0.56        26\n",
      "           8       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.69       227\n",
      "   macro avg       0.51      0.41      0.44       227\n",
      "weighted avg       0.67      0.69      0.67       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - more trees, limit depth\n",
    "rf_tuned = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=RANDOM_STATE)\n",
    "rf_tuned.fit(X_train_c_scaled, y_train_c)\n",
    "rf_tuned_pred = rf_tuned.predict(X_test_c_scaled)\n",
    "tuned_results['Random Forest'] = accuracy_score(y_test_c, rf_tuned_pred)\n",
    "print(f\"Random Forest Tuned Accuracy: {tuned_results['Random Forest']:.4f}\")\n",
    "print(classification_report(y_test_c, rf_tuned_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Tuned Accuracy: 0.6211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.17      0.17      0.17         6\n",
      "           5       0.63      0.67      0.65        98\n",
      "           6       0.62      0.64      0.63        94\n",
      "           7       0.68      0.50      0.58        26\n",
      "           8       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.62       227\n",
      "   macro avg       0.52      0.41      0.45       227\n",
      "weighted avg       0.62      0.62      0.62       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Network - add layer, regularization\n",
    "mlp_tuned = MLPClassifier(hidden_layer_sizes=(100, 50), alpha=0.01, max_iter=1000, random_state=RANDOM_STATE)\n",
    "mlp_tuned.fit(X_train_c_scaled, y_train_c)\n",
    "mlp_tuned_pred = mlp_tuned.predict(X_test_c_scaled)\n",
    "tuned_results['Neural Network'] = accuracy_score(y_test_c, mlp_tuned_pred)\n",
    "print(f\"Neural Network Tuned Accuracy: {tuned_results['Neural Network']:.4f}\")\n",
    "print(classification_report(y_test_c, mlp_tuned_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Tuned Accuracy: 0.5771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.63      0.72      0.68        98\n",
      "           6       0.53      0.59      0.56        94\n",
      "           7       0.45      0.19      0.27        26\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.58       227\n",
      "   macro avg       0.27      0.25      0.25       227\n",
      "weighted avg       0.54      0.58      0.55       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - adjust regularization\n",
    "lr_tuned = LogisticRegression(C=1.0, max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr_tuned.fit(X_train_c_scaled, y_train_c)\n",
    "lr_tuned_pred = lr_tuned.predict(X_test_c_scaled)\n",
    "tuned_results['Logistic Regression'] = accuracy_score(y_test_c, lr_tuned_pred)\n",
    "print(f\"Logistic Regression Tuned Accuracy: {tuned_results['Logistic Regression']:.4f}\")\n",
    "print(classification_report(y_test_c, lr_tuned_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Tuned Accuracy: 0.6872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.73      0.77      0.75        98\n",
      "           6       0.66      0.73      0.70        94\n",
      "           7       0.58      0.42      0.49        26\n",
      "           8       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.69       227\n",
      "   macro avg       0.50      0.40      0.43       227\n",
      "weighted avg       0.66      0.69      0.67       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN - adjust k and use distance weighting\n",
    "knn_tuned = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "knn_tuned.fit(X_train_c_scaled, y_train_c)\n",
    "knn_tuned_pred = knn_tuned.predict(X_test_c_scaled)\n",
    "tuned_results['KNN'] = accuracy_score(y_test_c, knn_tuned_pred)\n",
    "print(f\"KNN Tuned Accuracy: {tuned_results['KNN']:.4f}\")\n",
    "print(classification_report(y_test_c, knn_tuned_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL RESULTS: BASELINE vs TUNED (with Data Cleaning)\n",
      "============================================================\n",
      "Model                Baseline     Tuned        Improvement \n",
      "------------------------------------------------------------\n",
      "SVM                  0.6250       0.6300       +0.0050\n",
      "Random Forest        0.6813       0.6872       +0.0060\n",
      "Neural Network       0.6375       0.6211       -0.0164\n",
      "Logistic Regression  0.5906       0.5771       -0.0135\n",
      "KNN                  0.6094       0.6872       +0.0778\n",
      "\n",
      "Note: Tuned models use IQR outlier removal + hyperparameter tuning\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINAL RESULTS: BASELINE vs TUNED (with Data Cleaning)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} {'Baseline':<12} {'Tuned':<12} {'Improvement':<12}\")\n",
    "print(\"-\"*60)\n",
    "for model in baseline_results:\n",
    "    base = baseline_results[model]\n",
    "    tuned = tuned_results[model]\n",
    "    diff = tuned - base\n",
    "    print(f\"{model:<20} {base:<12.4f} {tuned:<12.4f} {diff:+.4f}\")\n",
    "\n",
    "print(\"\\nNote: Tuned models use IQR outlier removal + hyperparameter tuning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
